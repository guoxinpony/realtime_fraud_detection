x-airflow-common: &airflow-common
  image: airflow_realtime_fraud:2.10.5
  environment: &airflow-common-env
    # AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
    # AIRFLOW__SMTP__SMTP_HOST: 'smtp.gmail.com'
    # AIRFLOW__SMTP__SMTP_MAIL_FROM: ''
    # AIRFLOW__SMTP__SMTP_USER: ${AIRFLOW__SMTP__SMTP_USER}
    # AIRFLOW__SMTP__SMTP_PASSWORD: ${AIRFLOW__SMTP__SMTP_PASSWORD}
    # AIRFLOW__SMTP__SMTP_PORT: '587'
    MLFLOW_TRACKING_URI: 'http://mlflow-server:5500'   # mlflow server container required!!
    MLFLOW_S3_ENDPOINT_URL: 'http://minio:9000'        # minio server is required for store models
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    - ./models:/app/models
    - ./config.yaml:/app/config.yaml
    - ./.env:/app/.env
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on: &airflow-common-depends-on
    postgres:
      condition: service_healthy
    redis:
      condition: service_healthy
  networks:
    - realtime-fraud-detection


services:
  postgres:
    image: postgres:13
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 10s
      retries: 5
      start_period: 5s
    networks:
      - realtime-fraud-detection

  redis:
    image: redis:7.2-bookworm
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always
    networks:
      - realtime-fraud-detection


  kafka_broker:
    image: redpandadata/redpanda:v24.1.1
    container_name: kafka_broker
    restart: 
      unless-stopped
    command: >
      redpanda start
      --smp 1
      --overprovisioned
      --node-id 0
      --mode dev-container
      --set auto_create_topics_enabled=true
      --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      --advertise-kafka-addr internal://kafka_broker:9092,external://localhost:19092
      --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      --advertise-pandaproxy-addr internal://kafka_broker:8082,external://localhost:18082
      --rpc-addr kafka_broker:33145
      --advertise-rpc-addr kafka_broker:33145
    ports:
      - 19092:19092    # Kafka external
      - 18081:18081    # Schema Registry external
      - 18082:18082    # Pandaproxy external
      - 19644:9644     # Admin API external
    volumes:
      - redpanda-data:/var/lib/redpanda/data
    networks:
      - realtime-fraud-detection



  kafka_console:
    image: docker.redpanda.com/redpandadata/console:v2.7.2
    container_name: kafka_console
    depends_on:
      - kafka_broker
    environment:
      CONFIG_FILEPATH: /etc/console/config.yml
    volumes:
      - ./config/redpanda-console.yml:/etc/console/config.yml:ro
    ports:
      - "8090:8080"
    networks:
      - realtime-fraud-detection




  airflow-webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    <<: *airflow-common
    command: webserver
    container_name: airflow-webserver-fraud-detection
    ports:
      - "8080:8080"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://127.0.0.1:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    container_name: airflow-scheduler-fraud-detection
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8974/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-worker:
    <<: *airflow-common
    command: celery worker
    healthcheck:
      # yamllint disable rule:line-length
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    deploy:
      mode: replicated
      replicas: 2


  flower:
    <<: *airflow-common
    command: celery flower
    # profiles:
    #   - flower
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - realtime-fraud-detection


  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-init:
    <<: *airflow-common
    entrypoint: ["/bootstrap.sh"]
    container_name: airflow-init_realtime_fraud
    command: ["bash","-lc","echo init-only"]
    environment:
      <<: *airflow-common-env
      _AIRFLOW_WWW_USER_USERNAME: "admin"
      _AIRFLOW_WWW_USER_PASSWORD: "admin"
      _AIRFLOW_WWW_USER_FIRSTNAME: "Air"
      _AIRFLOW_WWW_USER_LASTNAME: "Flow"
      _AIRFLOW_WWW_USER_EMAIL: "admin@example.com"
    restart: "no"
    user: "0:0"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/sources
    healthcheck:
      test: ["CMD", "bash", "-lc", "airflow db check || airflow db init"]
      interval: 10s
      timeout: 10s
      retries: 5


  airflow-cli:
    <<: *airflow-common
    profiles:
      - debug
    container_name: airflow-cli
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: "0"
    command:
      - bash
      - -c
      - airflow


  # MINIO SERVER initial
  mc:
    image: minio/mc:RELEASE.2025-02-21T16-00-46Z
    platform: linux/amd64
    depends_on:
      - minio
    container_name: mc
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c "
      sh /tmp/wait-for-it.sh minio:9000 &&
      /usr/bin/mc alias set minio http://minio:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY} &&
      /usr/bin/mc mb minio/mlflow;
      exit 0;
      "
    volumes:
      - ./wait-for-it.sh:/tmp/wait-for-it.sh
    networks:
      - realtime-fraud-detection


  # MINIO: object storage, for machine learning models storage in the project
  minio:
    restart: always
    image: minio/minio:RELEASE.2025-02-28T09-55-16Z
    platform: linux/amd64
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ':9001' --address ':9000'
    environment:
      - MINIO_ROOT_USER=${MINIO_USERNAME}
      - MINIO_ROOT_PASSWORD=${MINIO_PASSWORD}
    volumes:
      - minio_data:/data
    networks:
      - realtime-fraud-detection

  mlflow-server:
    restart: always
    build: ./mlflow
    image: mlflow-server
    container_name: mlflow-server
    depends_on:
      - mc
      - postgres_mlflow
    ports:
      - "5500:5500"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: mlflow server --port 5500 --host 0.0.0.0 --backend-store-uri postgresql+psycopg2://mlflow:mlflow@postgres_mlflow/mlflow --default-artifact-root s3://mlflow
    networks:
      - realtime-fraud-detection


  postgres_mlflow:
    image: postgres:13
    container_name: postgres_mlflow
    restart: unless-stopped
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - postgres-db-volume_mlflow:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "mlflow" ]
      interval: 10s
      retries: 5
      start_period: 5s
    networks:
      - realtime-fraud-detection


  producer:
    build: ./producer
    env_file: .env
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 1G
    volumes:
      - ./data:/data
    command:
      - "--file"
      - "/data/fraud_detection_data.csv"
    networks:
      - realtime-fraud-detection



  test_data_feeder:
    build: ./producer
    container_name: test_data_feeder
    env_file: .env
    restart: unless-stopped
    depends_on:
      - kafka_broker
    volumes:
      - ./data:/data:ro
    command:
      - "--file"
      - "/data/fraud_detection_data.csv"
      - "--topic"
      - "fraud_test_data"
      - "--sleep"
      - "2"
    networks:
      - realtime-fraud-detection

  inference:
    build: ./inference
    env_file: .env
    volumes:
      - ./models:/app/models
      - ./config.yaml:/app/config.yaml
      - ./env:/app/.env
      - ./inference/main.py:/app/main.py
    networks:
      - realtime-fraud-detection


volumes:
  postgres-db-volume:
  minio_data:
  postgres-db-volume_mlflow:
  redpanda-data:

networks:
  realtime-fraud-detection:
